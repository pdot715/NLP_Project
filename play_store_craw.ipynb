{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding:utf-8 -*-\n",
    "\n",
    "import time\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import sys, io\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.by import By\n",
    "import selenium.webdriver.support.expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "# 앱 주소 크롤링\n",
    "import lxml\n",
    "import requests\n",
    "\n",
    "import urllib.request\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "# Append your app store urls here\n",
    "# 여기에 크롤링 할 앱의 주소 넣기\n",
    "urls = []\n",
    "path = os.getcwd()\n",
    "\n",
    "# https://github.com/nahida-uap/Crawler-for-Google-Play-store를 참고함\n",
    "# 참고한 소스 저자 @author Nahida Sultana Chowdhury <nschowdh@iu.edu>\n",
    "#additionally add CSV file method here...\n",
    "\n",
    "non_bmp_map = dict.fromkeys(range(0x10000, sys.maxunicode + 1), 0xfffd)\n",
    "\n",
    "# 크롬 드라이버 경로\n",
    "# http://chromedriver.chromium.org/downloads 여기서 다운 받아서 같은 폴더에 넣어주기\n",
    "chromedriver_loc = \"./chromedriver\"\n",
    "driver = webdriver.Chrome(executable_path=chromedriver_loc)\n",
    "wait = WebDriverWait( driver, 10 )\n",
    "\n",
    "\n",
    "# 크롤링 할 게임들 추가하기\n",
    "def get_link(target_url):\n",
    "    \n",
    "    response = requests.get(target_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    ytds = soup.find_all('a', {'class' : 'card-click-target'})\n",
    "    \n",
    "    for ytd in ytds:\n",
    "        aria = ytd.get('aria-hidden', '')\n",
    "        if(aria == 'true'):\n",
    "            continue\n",
    "        \n",
    "        link = 'https://play.google.com' + ytd.get('href', '')\n",
    "        print(link)\n",
    "        urls.append(link)\n",
    "\n",
    "# 리뷰 가져오기            \n",
    "def get_review():\n",
    "    \n",
    "    for url in urls:\n",
    "        #print(url)\n",
    "        time.sleep(1)\n",
    "        try:\n",
    "            driver.get(url+'&hl=ko')\n",
    "            driver.maximize_window()\n",
    "\n",
    "            page = driver.page_source\n",
    "\n",
    "            soup_expatistan = BeautifulSoup(page, \"html.parser\")\n",
    "            expatistan_table = soup_expatistan.find(\"h1\", class_=\"AHFaub\")\n",
    "            print(\"App name: \", expatistan_table.string)\n",
    "            \n",
    "            get_photo(url+'&hl=ko', expatistan_table.string)\n",
    "\n",
    "            try:\n",
    "                read_all_reviews_button = driver.find_element_by_xpath('//*[@id=\"fcxH9b\"]/div[4]/c-wiz/div/div[2]/div/div[1]/div/div/div/div[6]/div/content')\n",
    "\n",
    "                read_all_reviews_button.click()\n",
    "\n",
    "                actions = ActionChains(driver)\n",
    "                # 더 보기 버튼 나올때까지 \n",
    "                for _ in range(15):\n",
    "                    actions.send_keys(Keys.SPACE).perform()\n",
    "                    time.sleep(1)\n",
    "                try:\n",
    "                    show_more_button = driver.find_element_by_xpath('//*[@id=\"fcxH9b\"]/div[4]/c-wiz[2]/div/div[2]/div/div[1]/div/div/div/div[2]/div[2]/div/content')\n",
    "\n",
    "                    for i in range(0,5):\n",
    "                        try:\n",
    "                            show_more_button.click()\n",
    "                # 이부분 range 안에 잇는 숫자를 늘리면 더 많이 크롤링 됐음\n",
    "                # 50으로 했을때 약 5000개\n",
    "                # 5일때 약 1500개\n",
    "                            for _ in range(5):   #Adjust this range according to your need, I mean how far you wanna go down.\n",
    "                                actions.send_keys(Keys.SPACE).perform()\n",
    "                                time.sleep(1)\n",
    "                        except Exception:\n",
    "                            time.sleep(1)\n",
    "                except Exception:\n",
    "                    time.sleep(1)\n",
    "\n",
    "                reviews_div = driver.find_element_by_xpath('//*[@id=\"fcxH9b\"]/div[4]/c-wiz[2]/div/div[2]/div/div[1]/div/div/div/div[2]/div').get_attribute(\"innerHTML\")\n",
    "\n",
    "                soup_expatistan = BeautifulSoup(reviews_div, \"html.parser\")\n",
    "\n",
    "                expand_pages = soup_expatistan.find_all(\"div\", class_=\"d15Mdf bAhLNe\")\n",
    "\n",
    "                try:\n",
    "                    dir_path = path + '\\\\' + expatistan_table.string  ##진짜 app_name으로 변경하기\n",
    "\n",
    "                    # dir 있나 확인\n",
    "                    try:\n",
    "                        if not(os.path.isdir(dir_path)):\n",
    "                            os.mkdir(dir_path)\n",
    "                    except OSError as e:\n",
    "                        if e.errno != errno.EEXIST:\n",
    "                            print(\"Failed to create directory!!!!!\")\n",
    "                            raise\n",
    "                    myFile = open(dir_path + '\\\\' + 'review.csv',\"w\", newline='', encoding=\"utf-8\")\n",
    "                    with myFile:\n",
    "                        writer = csv.writer(myFile)\n",
    "                        for expand_page in expand_pages:\n",
    "                            ind_rev = expand_page.find(\"span\", class_=\"p2TkOb\")\n",
    "                            ind_rev_date = expand_page.find(\"div\", class_=\"UD7Dzf\")\n",
    "\n",
    "                            num_of_star = 0\n",
    "                            star_count = expand_page.find_all(\"div\", class_=\"vQHuPe bUWb7c\")    \n",
    "                            for star in star_count:\n",
    "                                num_of_star = num_of_star + 1\n",
    "                            #print(num_of_star)\n",
    "\n",
    "                            # 밑 3코드로 한글 문자 encode 하고 decode 해서 넣어줌\n",
    "                            utf8_text = ind_rev.text.encode(\"utf-8\")\n",
    "                            utf8_date = ind_rev_date.text.encode(\"utf-8\")\n",
    "                            csvRow = [num_of_star, utf8_text.decode('utf-8'), utf8_date.decode('utf-8')]\n",
    "\n",
    "                            writer.writerow(csvRow)\n",
    "                    myFile.close()\n",
    "                except Exception:\n",
    "                    print(\"file open error\")\n",
    "            except Exception:\n",
    "                time.sleep(1)\n",
    "        except Exception:\n",
    "                time.sleep(1)\n",
    "\n",
    "# 게임 이미지 가져오는 함수 (앱 주소, 앱 이름)\n",
    "def get_photo(target_url, app_name):\n",
    "    dir_path = path + '\\\\' + app_name   ##진짜 app_name으로 변경하기\n",
    "    print(dir_path)\n",
    "    # dir 있나 확인\n",
    "    try:\n",
    "        if not(os.path.isdir(dir_path)):\n",
    "            os.mkdir(dir_path)\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            print(\"Failed to create directory!!!!!\")\n",
    "            raise\n",
    "\n",
    "    response = requests.get(target_url)    ##url로부터 response 끌고와 html소스 파싱\n",
    "    soup = BeautifulSoup(response.text, \"lxml\")\n",
    "    ytds = soup.find_all('button', {'class' : 'NIc6yf'})\n",
    "  \n",
    "    i = 0  #img_index\n",
    "    \n",
    "    for ytd in ytds :\n",
    "        link = ytd.find('img')\n",
    "        download_link = link.get('src', '')\n",
    "        savename = str(i) + \".png\"  # app name + str(i)로 변경 \n",
    "        print(download_link)\n",
    "        \n",
    "        if(download_link == ''):\n",
    "            continue\n",
    "            \n",
    "        urllib.request.urlretrieve(download_link, dir_path + '\\\\' + savename)\n",
    "        \n",
    "        print(\"saved\")\n",
    "        i = i + 1\n",
    "        if (i == (len(ytds) / 3)):\n",
    "            break  \n",
    "                \n",
    "\n",
    "# 크롤링 할 항목 (예를 들면 인기순위 주소) 넣어주기\n",
    "# gl은 국가 코드 (한국에서의 랭킹이 필요하니까 KR 넣어줌)\n",
    "target_url = 'https://play.google.com/store/apps/category/GAME/collection/topselling_free?gl=KR'\n",
    "get_link(target_url)\n",
    "get_review()\n",
    "\n",
    "                \n",
    "driver.quit()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
